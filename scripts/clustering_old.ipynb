{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import folium\n",
    "import branca.colormap as cm  # Add this import\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import MarkerCluster\n",
    "from shapely.ops import unary_union\n",
    "from sklearn.neighbors import BallTree\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# import datasets\n",
    "existing_isochrones = gpd.read_file('../data/derived_data/iso_merged.gpkg')\n",
    "flats_pop = gpd.read_file('../data/derived_data/flats_population.gpkg')\n",
    "rcps= rcps = gpd.read_file('../data/raw_data/geodata_stadt_Zuerich/recycling_sammelstellen/data/stzh.poi_sammelstelle_view.shp')\n",
    "flats_duration= gpd.read_file('../data/derived_data/flats_duration.gpkg')\n",
    "rcps.to_crs('EPSG:4326', inplace=True)\n",
    "potential_sites= gpd.read_file('../data/derived_data/all_pot_sites.gpkg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_isochrones_preserve_time(isochrones_gdf):\n",
    "    \"\"\"\n",
    "    Merge isochrones preserving lower time values.\n",
    "\n",
    "    Parameters:\n",
    "    - isochrones_gdf: GeoDataFrame with isochrones and 'time' attribute.\n",
    "\n",
    "    Returns:\n",
    "    - GeoDataFrame with merged isochrones.\n",
    "    \"\"\"\n",
    "    # Ensure CRS is EPSG:4326\n",
    "    if isochrones_gdf.crs != \"EPSG:4326\":\n",
    "        isochrones_gdf = isochrones_gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # Sort isochrones by 'time' ascending\n",
    "    isochrones_sorted = isochrones_gdf.sort_values(by='time')\n",
    "\n",
    "    merged_isochrones = gpd.GeoDataFrame(columns=isochrones_sorted.columns, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Initialize an empty geometry for subtraction\n",
    "    accumulated_geom = None\n",
    "\n",
    "    for _, row in isochrones_sorted.iterrows():\n",
    "        current_geom = row.geometry\n",
    "        current_time = row['time']\n",
    "\n",
    "        if accumulated_geom:\n",
    "            remaining_geom = current_geom.difference(accumulated_geom)\n",
    "        else:\n",
    "            remaining_geom = current_geom\n",
    "\n",
    "        if not remaining_geom.is_empty:\n",
    "            new_row = row.copy()\n",
    "            new_row.geometry = remaining_geom\n",
    "            # Ensure the new_row GeoDataFrame has the correct CRS\n",
    "            new_row = gpd.GeoDataFrame([new_row], crs=\"EPSG:4326\")\n",
    "            merged_isochrones = pd.concat([merged_isochrones, new_row], ignore_index=True)\n",
    "            # Update accumulated geometry\n",
    "            if accumulated_geom:\n",
    "                accumulated_geom = unary_union([accumulated_geom, remaining_geom])\n",
    "            else:\n",
    "                accumulated_geom = remaining_geom\n",
    "    return merged_isochrones\n",
    "\n",
    "\n",
    "merged_isochrones = merge_isochrones_preserve_time(existing_isochrones)\n",
    "merged_isochrones.to_file('../data/derived_data/merged_isochrones.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject flats_pop to match merged_isochrones CRS\n",
    "flats_pop_4326 = flats_pop.to_crs(merged_isochrones.crs)\n",
    "\n",
    "# Merge all isochrones into a single geometry\n",
    "iso_union = merged_isochrones.unary_union\n",
    "\n",
    "# Identify flats outside any isochrones\n",
    "flats_outside = flats_pop_4326[~flats_pop_4326.geometry.within(iso_union)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to centroids and set up the data for clustering\n",
    "X = pd.DataFrame({\n",
    "    'x': flats_outside.geometry.x,\n",
    "    'y': flats_outside.geometry.y,\n",
    "    'population': flats_outside['est_pop']\n",
    "})\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "db = DBSCAN(eps=0.005, min_samples=20).fit(X[['x', 'y']])\n",
    "X['cluster'] = db.labels_\n",
    "\n",
    "# Remove noise points\n",
    "clusters = X[X['cluster'] != -1]\n",
    "\n",
    "# Calculate cluster centers weighted by population\n",
    "cluster_centers = clusters.groupby('cluster').apply(\n",
    "    lambda df: pd.Series({\n",
    "        'x': (df['x'] * df['population']).sum() / df['population'].sum(),\n",
    "        'y': (df['y'] * df['population']).sum() / df['population'].sum()\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "# Create GeoDataFrame for new collection points\n",
    "new_points = gpd.GeoDataFrame(\n",
    "    cluster_centers,\n",
    "    geometry=gpd.points_from_xy(cluster_centers['x'], cluster_centers['y']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = merged_isochrones.geometry.unary_union.centroid\n",
    "\n",
    "# Initialize the folium map centered on the centroid with specified tiles\n",
    "m = folium.Map(location=[centroid.y, centroid.x], zoom_start=12)\n",
    "\n",
    "# Convert 'time' column to numeric and convert seconds to minutes\n",
    "merged_isochrones['time'] = pd.to_numeric(merged_isochrones['time']) / 60\n",
    "\n",
    "# Define a viridis colormap based on time (in minutes)\n",
    "colormap = cm.linear.viridis.scale(\n",
    "    merged_isochrones['time'].min(),\n",
    "    merged_isochrones['time'].max()\n",
    ")\n",
    "colormap.caption = 'Walking Time (minutes)'\n",
    "colormap.add_to(m)\n",
    "\n",
    "folium.GeoJson(\n",
    "    merged_isochrones,\n",
    "    name='Merged Isochrones',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': colormap(float(feature['properties']['time'])),\n",
    "        'color': colormap(float(feature['properties']['time'])),\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.5,\n",
    "    },\n",
    "    show=False\n",
    ").add_to(m)\n",
    "\n",
    "# Add RCP dataset to the map with green markers\n",
    "rcp_layer = folium.FeatureGroup(name='RCP Locations')\n",
    "for _, row in rcps.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        popup=row['adresse'],\n",
    "        icon=folium.Icon(color='green', icon='recycle', prefix='fa')\n",
    "    ).add_to(rcp_layer)\n",
    "rcp_layer.add_to(m)\n",
    "\n",
    "# Add flats_outside as red CircleMarkers within a FeatureGroup\n",
    "flats_outside_layer = folium.FeatureGroup(name='Flats Outside', show=False)\n",
    "for _, row in flats_outside.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=3,\n",
    "        fill=True,\n",
    "        color='red',\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.6,\n",
    "        popup=f'Population: {row.est_pop:.2f}'\n",
    "    ).add_to(flats_outside_layer)\n",
    "flats_outside_layer.add_to(m)\n",
    "\n",
    "# Add new collection points to the map with blue + sign markers\n",
    "new_rcp_layer = folium.FeatureGroup(name='New RCP Locations', show=False)\n",
    "for _, point in new_points.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[point.geometry.y, point.geometry.x],\n",
    "        icon=folium.Icon(color='blue', icon='plus', prefix='fa')\n",
    "    ).add_to(new_rcp_layer)\n",
    "new_rcp_layer.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "m.save('../data/plots/map_all_steps_old.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter potential sites with status \"potential\"\n",
    "potential_pot = potential_sites[potential_sites[\"status\"] == \"potential\"].copy()\n",
    "\n",
    "# Reproject potential sites to EPSG:4326 if needed\n",
    "if potential_pot.crs != \"EPSG:4326\":\n",
    "    potential_pot = potential_pot.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Create a GeoDataFrame of cluster centres from the cluster_centers DataFrame\n",
    "cluster_centers_gdf = gpd.GeoDataFrame(\n",
    "    cluster_centers,\n",
    "    geometry=gpd.points_from_xy(cluster_centers['x'], cluster_centers['y']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# For each cluster centre, find the closest potential location\n",
    "closest_locations = []\n",
    "for idx, centre in cluster_centers_gdf.iterrows():\n",
    "    # Compute distances from this centre to all potential sites\n",
    "    potential_pot['dist'] = potential_pot.geometry.distance(centre.geometry)\n",
    "    # Get the potential site with the minimum distance\n",
    "    min_idx = potential_pot['dist'].idxmin()\n",
    "    min_loc = potential_pot.loc[min_idx]\n",
    "    closest_locations.append({\n",
    "         'potential_ID': min_loc['ID'],\n",
    "         'geometry': min_loc.geometry\n",
    "    })\n",
    "\n",
    "closest_locations_gdf = gpd.GeoDataFrame(closest_locations, geometry='geometry', crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame for existing RCPs\n",
    "existing = rcps.copy()\n",
    "existing['id'] = ['existing_' + str(i + 1) for i in range(len(existing))]\n",
    "\n",
    "# Create a GeoDataFrame for potential RCPs\n",
    "potentials = closest_locations_gdf.copy()\n",
    "potentials['id'] = ['pot_' + str(i + 1) for i in range(len(potentials))]\n",
    "\n",
    "# Combine the two groups and then select only the required columns\n",
    "rcp_summary = pd.concat([\n",
    "    existing[['geometry', 'id']], \n",
    "    potentials[['geometry', 'id']]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# export to file\n",
    "rcp_summary.to_file('../data/derived_data/rcps_clustering_iso.gpkg', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
